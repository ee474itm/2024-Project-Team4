{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/20200884/.conda/envs/alacen/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Dora directory: /tmp/audiocraft_20200884\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from natsort import natsorted\n",
    "import torch\n",
    "\n",
    "from src.alacen.alacen import ALACen\n",
    "from src.alacen.asr.whisper import Whisper\n",
    "from src.alacen.paraphrase.pegasus import PegasusAlacen\n",
    "from src.alacen.tts.voicecraft.voicecraft import VoiceCraftTTS, VoiceCraftArgs\n",
    "from src.alacen.lipsync.diff2lip.diff2lip import Diff2Lip, Diff2LipArgs\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "asr = Whisper()\n",
    "paraphrase = PegasusAlacen()\n",
    "tts = VoiceCraftTTS(model_name=\"330M_TTSEnhanced\")\n",
    "lipsync = Diff2Lip(Diff2LipArgs())\n",
    "\n",
    "alacen = ALACen(asr, paraphrase, tts, lipsync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE = True\n",
    "VIDEO_DIR = Path(\"videos\")\n",
    "OUT_DIR = Path(\"output\")\n",
    "NUM_PARAPHRASES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('videos/vid2.mp4'), PosixPath('videos/vid2_1.mp4')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_list = natsorted(\n",
    "    [f for f in os.listdir(VIDEO_DIR) if os.path.isfile(VIDEO_DIR / f)]\n",
    ")\n",
    "video_list = [VIDEO_DIR / f for f in video_list]\n",
    "video_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run ALACen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-30 11:19:28,088 | alacen | DEBUG] Extracting audio from video...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video 1: videos/vid2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-30 11:19:28,490 | alacen | DEBUG] Performing speech recognition...\n",
      "[2024-05-30 11:19:33,144 | alacen | DEBUG] Transcript:  If I ever find one of these lying around again, I swear to fucking God, I will stop being so polite.\n",
      "[2024-05-30 11:19:33,147 | alacen | DEBUG] Generating paraphrase...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please choose the best paraphrase among the following:\n",
      "1. If I ever find one of these lying around again, I swear to myself, I will stop being so polite.\n",
      "2. If I ever find one of these lying around again, I swear to God, I will stop being so polite.\n",
      "3. If I ever encounter one of these individuals again, I will not hesitate to express my strong disapproval.\n",
      "4. If I ever find one of these again, I swear to God, I will stop being so polite.\n",
      "5. I'm so used to being so polite, I might as well stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-30 11:19:42,659 | alacen | DEBUG] Generating new audio...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected paraphrase: If I ever find one of these again, I swear to God, I will stop being so polite.\n",
      "Generated audio file saved to 'output/vid2_gen_seed-1.wav'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-30 11:22:13,787 | alacen | DEBUG] Generating lip-synced video...\n",
      "DEBUG:alacen:Generating lip-synced video...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI.COMM_WORLD.Get_rank() 0\n",
      "os.environ[\"CUDA_VISIBLE_DEVICES\"] 0\n",
      "MPI.COMM_WORLD.Get_rank() 1\n",
      "os.environ[\"CUDA_VISIBLE_DEVICES\"] 1\n",
      "MPI.COMM_WORLD.Get_rank() 2\n",
      "os.environ[\"CUDA_VISIBLE_DEVICES\"] 2\n",
      "Recovering from OOM error; New batch size: 32\n",
      "Recovering from OOM error; New batch size: 32\n",
      "Recovering from OOM error; New batch size: 32\n",
      "Recovering from OOM error; New batch size: 16\n",
      "Recovering from OOM error; New batch size: 16\n",
      "Recovering from OOM error; New batch size: 16\n",
      "Recovering from OOM error; New batch size: 8\n",
      "Time taken for sampling,  48.52311706542969 ,time without all  gather,  47.948182106018066 ,frames/gpu,  109 ,total frames,  109\n",
      "(71680,) (109, 540, 960, 3)\n",
      "(69760,) (109, 540, 960, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-30 11:26:57,051 | alacen | DEBUG] DONE\n",
      "DEBUG:alacen:DONE\n",
      "[2024-05-30 11:26:57,057 | alacen | DEBUG] Extracting audio from video...\n",
      "DEBUG:alacen:Extracting audio from video...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Video 2: videos/vid2_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-30 11:26:57,444 | alacen | DEBUG] Performing speech recognition...\n",
      "DEBUG:alacen:Performing speech recognition...\n",
      "[2024-05-30 11:26:59,509 | alacen | DEBUG] Transcript:  If I ever find one of these lying around again, I swear to fucking God, I will stop being so polite.\n",
      "DEBUG:alacen:Transcript:  If I ever find one of these lying around again, I swear to fucking God, I will stop being so polite.\n",
      "[2024-05-30 11:26:59,512 | alacen | DEBUG] Generating paraphrase...\n",
      "DEBUG:alacen:Generating paraphrase...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please choose the best paraphrase among the following:\n",
      "1. If I ever find one of these lying around again, I swear to God, I will stop being so polite.\n",
      "2. If I ever find one of these lying around again, I swear to God, I will stop being so polite.\n",
      "3. If I ever encounter one of these individuals again, I would respectfully decline to engage in such language.\n",
      "4. If I ever find one of these lying around again, I vow to stop being so polite.\n",
      "5. If I ever encounter one of these individuals again, I will be forced to reconsider my approach to this situation.\n",
      "1. If I ever find one of these lying around again, I swear to God, I will stop being so polite.\n",
      "2. If I ever find one of these lying around again, I swear to God, I will stop being so polite.\n",
      "3. If I ever find one of these lying around again, I swear to God, I will stop being so polite.\n",
      "4. If I ever encounter one of these individuals again, I will be forced to reconsider my approach to life.\n",
      "5. If I ever find one of these again, I promise to be even more mindful of my words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-30 11:32:07,996 | alacen | DEBUG] Generating new audio...\n",
      "DEBUG:alacen:Generating new audio...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected paraphrase: If I ever find one of these lying around again, I swear to God, I will stop being so polite.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:phonemizer:words count mismatch on 500.0% of the lines (5/1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated audio file saved to 'output/vid2_1_gen_seed-1.wav'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-30 11:35:23,982 | alacen | DEBUG] Generating lip-synced video...\n",
      "DEBUG:alacen:Generating lip-synced video...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI.COMM_WORLD.Get_rank() 2\n",
      "os.environ[\"CUDA_VISIBLE_DEVICES\"] 2\n",
      "MPI.COMM_WORLD.Get_rank() 0\n",
      "os.environ[\"CUDA_VISIBLE_DEVICES\"] 0\n",
      "MPI.COMM_WORLD.Get_rank() 1\n",
      "os.environ[\"CUDA_VISIBLE_DEVICES\"] 1\n",
      "Recovering from OOM error; New batch size: 32\n",
      "Recovering from OOM error; New batch size: 32\n",
      "Recovering from OOM error; New batch size: 32\n",
      "Recovering from OOM error; New batch size: 16\n",
      "Recovering from OOM error; New batch size: 16\n",
      "Recovering from OOM error; New batch size: 16\n",
      "Recovering from OOM error; New batch size: 8\n",
      "Time taken for sampling,  34.01254940032959 ,time without all  gather,  33.17655611038208 ,frames/gpu,  78 ,total frames,  78\n",
      "(52160,) (78, 540, 960, 3)\n",
      "(49920,) (78, 540, 960, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-30 11:39:51,533 | alacen | DEBUG] DONE\n",
      "DEBUG:alacen:DONE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, video in enumerate(video_list, 1):\n",
    "    print(f\"Video {i}: {video}\")\n",
    "    alacen.run(\n",
    "        video,\n",
    "        OUT_DIR,\n",
    "        VoiceCraftArgs,\n",
    "        num_paraphrases=NUM_PARAPHRASES,\n",
    "        device=device,\n",
    "        verbose=VERBOSE,\n",
    "        clean_up=True,\n",
    "    )\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alacen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
